{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Supervised Learning\n",
    "### Building a Student Intervention System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification vs Regression\n",
    "\n",
    "Your goal is to identify students who might need early intervention - which type of supervised machine learning problem is this, classification or regression? Why?\n",
    "\n",
    "The type of problem is 'Classification' as the objective is to find out the students will pass or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring the Data\n",
    "\n",
    "Let's go ahead and read in the student dataset first.\n",
    "\n",
    "_To execute a code cell, click inside it and press **Shift+Enter**._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student data read successfully!\n"
     ]
    }
   ],
   "source": [
    "# Read student data\n",
    "student_data = pd.read_csv(\"C:\\Users\\marimuthuananthavelu\\Desktop\\Student-Intervention-System_Udacity_Marimuthu\\student_intervention\\student-data.csv\")\n",
    "print \"Student data read successfully!\"\n",
    "# Note: The last column 'passed' is the target/label, all other are feature columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, can you find out the following facts about the dataset?\n",
    "- Total number of students\n",
    "- Number of students who passed\n",
    "- Number of students who failed\n",
    "- Graduation rate of the class (%)\n",
    "- Number of features\n",
    "\n",
    "_Use the code block below to compute these values. Instructions/steps are marked using **TODO**s._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students: 395\n",
      "Number of students who passed: 265\n",
      "Number of students who failed: 130\n",
      "Number of features: 30\n",
      "Graduation rate of the class: 67.09%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute desired values - replace each '?' with an appropriate expression/function call\n",
    "n_students = len(student_data)\n",
    "n_features = student_data.shape[1]-1\n",
    "n_passed = len(student_data[student_data['passed']=='yes'])\n",
    "n_failed = len(student_data[student_data['passed']=='no'])\n",
    "grad_rate = 100.0* n_passed/n_students\n",
    "print \"Total number of students: {}\".format(n_students)\n",
    "print \"Number of students who passed: {}\".format(n_passed)\n",
    "print \"Number of students who failed: {}\".format(n_failed)\n",
    "print \"Number of features: {}\".format(n_features)\n",
    "print \"Graduation rate of the class: {:.2f}%\".format(grad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing the Data\n",
    "In this section, we will prepare the data for modeling, training and testing.\n",
    "\n",
    "### Identify feature and target columns\n",
    "It is often the case that the data you obtain contains non-numeric features. This can be a problem, as most machine learning algorithms expect numeric data to perform computations with.\n",
    "\n",
    "Let's first separate our data into feature and target columns, and see if any features are non-numeric.<br/>\n",
    "**Note**: For this dataset, the last column (`'passed'`) is the target or label we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature column(s):-\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "Target column: passed\n",
      "\n",
      "Feature values:-\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract feature (X) and target (y) columns\n",
    "feature_cols = list(student_data.columns[:-1])  # all columns but last are features\n",
    "target_col = student_data.columns[-1]  # last column is the target/label\n",
    "print \"Feature column(s):-\\n{}\".format(feature_cols)\n",
    "print \"Target column: {}\".format(target_col)\n",
    "\n",
    "X_all = student_data[feature_cols]  # feature values for all students\n",
    "y_all = student_data[target_col]  # corresponding targets/labels\n",
    "print \"\\nFeature values:-\"\n",
    "print X_all.head()  # print the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess feature columns\n",
    "\n",
    "As you can see, there are several non-numeric columns that need to be converted! Many of them are simply `yes`/`no`, e.g. `internet`. These can be reasonably converted into `1`/`0` (binary) values.\n",
    "\n",
    "Other columns, like `Mjob` and `Fjob`, have more than two values, and are known as _categorical variables_. The recommended way to handle such a column is to create as many columns as possible values (e.g. `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc.), and assign a `1` to one of them and `0` to all others.\n",
    "\n",
    "These generated columns are sometimes called _dummy variables_, and we will use the [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) function to perform this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48):-\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess feature columns\n",
    "def preprocess_features(X):\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If data type is non-numeric, try to replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "        # Note: This should change the data type for yes/no columns to int\n",
    "\n",
    "        # If still non-numeric, convert to one or more dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)  # e.g. 'school' => 'school_GP', 'school_MS'\n",
    "\n",
    "        outX = outX.join(col_data)  # collect column(s) in output dataframe\n",
    "\n",
    "    return outX\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({}):-\\n{}\".format(len(X_all.columns), list(X_all.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test sets\n",
    "\n",
    "So far, we have converted all _categorical_ features into numeric values. In this next step, we split the data (both features and corresponding labels) into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 300 samples\n",
      "Test set: 95 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# First, decide how many training vs test samples you want\n",
    "num_all = student_data.shape[0]  # same as len(student_data)\n",
    "num_train = 300  # about 75% of the data\n",
    "num_test = num_all - num_train\n",
    "\n",
    "# TODO: Then, select features (X) and corresponding labels (y) for the training and test sets\n",
    "# Note: Shuffle the data or randomly select samples to avoid any bias due to ordering in the dataset\n",
    "\n",
    "X_train,X_test,y_train,y_test = cross_validation.train_test_split(X_all,y_all,train_size=300)\n",
    "\n",
    "print \"Training set: {} samples\".format(X_train.shape[0])\n",
    "print \"Test set: {} samples\".format(X_test.shape[0])\n",
    "# Note: If you need a validation set, extract it from within training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluating Models\n",
    "Choose 3 supervised learning models that are available in scikit-learn, and appropriate for this problem. For each model:\n",
    "\n",
    "- What are the general applications of this model? What are its strengths and weaknesses?\n",
    "- Given what you know about the data so far, why did you choose this model to apply?\n",
    "- Fit this model to the training data, try to predict labels (for both training and test sets), and measure the F<sub>1</sub> score. Repeat this process with different training set sizes (100, 200, 300), keeping test set constant.\n",
    "\n",
    "Produce a table showing training time, prediction time, F<sub>1</sub> score on training set and F<sub>1</sub> score on test set, for each training set size.\n",
    "\n",
    "Note: You need to produce 3 such tables - one for each model.\n",
    "\n",
    "\n",
    "The 3 supervised models used for solving the problem. They are:\n",
    "\n",
    "\n",
    "\n",
    "1. Decision Trees\n",
    "2. Gaussian Naive Bayes\n",
    "3. Support Vector Machines\n",
    "\n",
    "1. Decision Trees\n",
    "\n",
    "The Decisition Tree model that predicts the value of a target variable with the help of learning simple decision rules from the data features.\n",
    "\n",
    "The strengths and weaknesses of Decistion trees are;\n",
    "\n",
    "Strengths(I,II):\n",
    "\n",
    "1. Decision Trees are very flexible, easy to understand, and easy to debug.One of the coolest things about Decision Trees is they only need a table of data and they will build a classifier directly from that data without needing any up front design work to take place. Able to handle both numerical and categorical data. Other techniques are usually specialised in analysing datasets that have only one type of variable.(I,IV)\n",
    "\n",
    "2. Requires little data preparation. Other techniques often require data normalisation, dummy variables need to be created and blank values to be removed. Note however that this module does not support missing values.(I)\n",
    "\n",
    "3. The cost of using the tree (i.e., predicting data) is logarithmic in the number of data points used to train the tree.(I)\n",
    "\n",
    "4. Able to handle multi-output problems.\n",
    "\n",
    "5. Uses a white box model. If a given situation is observable in a model, the explanation for the condition is easily explained by boolean logic. By contrast, in a black box model (e.g., in an artificial neural network), results may be more difficult to interpret.\n",
    "\n",
    "6. Possible to validate a model using statistical tests. That makes it possible to account for the reliability of the model.\n",
    "\n",
    "7. Performs well even if its assumptions are somewhat violated by the true model from which the data were generated.\n",
    "\n",
    "8. Addresses non-linearity.\n",
    "\n",
    "Weaknesses(I,III,IV):\n",
    "\n",
    "1. They overfit. Splitting a lot leads to complex trees and raises probability you are overfitting. Decision-tree learners can create over-complex trees that do not generalise the data well. One require to prune the trees to overcome this issue or setting the minimum number of samples required at a leaf node or setting the maximum depth of the tree are necessary to avoid this problem. One does not have any upfront design cost due to its simplicity, but one will pay that back on tuning the trees performance.(I,IV)\n",
    "\n",
    "2. Instability : Decision trees can be unstable because small variations in the data might result in a completely different tree being generated. This problem is mitigated by using decision trees within an ensemble.(III)\n",
    "\n",
    "3. The problem of learning an optimal decision tree is known to be NP-complete under several aspects of optimality and even for simple concepts. Consequently, practical decision-tree learning algorithms are based on heuristic algorithms such as the greedy algorithm where locally optimal decisions are made at each node. Such algorithms cannot guarantee to return the globally optimal decision tree. This can be mitigated by training multiple trees in an ensemble learner, where the features and samples are randomly sampled with replacement.(I)\n",
    "\n",
    "4. There are concepts that are hard to learn because decision trees do not express them easily, such as XOR, parity or multiplexer problems.(I)\n",
    "\n",
    "5. Decision tree learners create biased trees if some classes dominate. It is therefore recommended to balance the dataset prior to fitting with the decision tree.(I)\n",
    "\n",
    "References:\n",
    "\n",
    "(I) http://scikit-learn.org/stable/modules/tree.html\n",
    "(II) https://www.quora.com/What-are-the-advantages-of-using-a-decision-tree-for-classification\n",
    "(III) https://www.quora.com/What-are-the-disadvantages-of-using-a-decision-tree-for-classification\n",
    "(IV) http://stackoverflow.com/questions/10317885/decision-tree-vs-naive-bayes-classifier\n",
    "\n",
    "\n",
    "Reason for considering Decision Trees:\n",
    "\n",
    "a. Decision trees is able to work with both numerical categorical variables unlike other models and Decistion trees take little efforts for Data preparation. Due to the content and the efforts for data preparation, i preferred Decision trees as one of the algorithm.\n",
    "\n",
    "b. Decision trees is simple to understand and interpret. With respect to the student data, i do visualize how the decistion trees will create leafs and nodes with respect to number of features and 2 possible outcomes i.e.'yes' or 'no'. Easy to interpret overall.\n",
    "\n",
    "\n",
    "2. Gaussian Naive Bayes\n",
    "\n",
    "Strengths (I,III):\n",
    "1.Simple in comparison,fast to train and fast to classify.\n",
    "2.Not sensitive to irrelevant features (see #1 in weaknesses)\n",
    "3.Good for a smaller dataset.\n",
    "4.Handles streaming data well(III)\n",
    "5. Bayes is based upon the conditional probability. Their answers are in terms of probabilities i.e. P(yes)=95 %,P(no)= 5%.\n",
    "\n",
    "Weaknesses (II,III):\n",
    "1.Assumes independence of Fearues\n",
    "2. High bias classifier due to its split and narrowing. (III)\n",
    "\n",
    "References:\n",
    "\n",
    "(I) https://books.google.ca/books?id=3DPcCgAAQBAJ&pg=PT139&lpg=PT139&dq=naive+Bayes#v=onepage&q=naive%20Bayes&f=false\n",
    "\n",
    "(II) http://www.cs.ucr.edu/~eamonn/CE/Bayesian%20Classification%20withInsect_examples.pdf\n",
    "\n",
    "(III) https://www.quora.com/What-are-the-advantages-of-different-classification-algorithms\n",
    "\n",
    "Reason for considering Naive Bayes:\n",
    "\n",
    "a. They are based upon conditional probability. Since in our case, the students performances are expected to be classified, my intuition is that finding the probability whether the students will pass or not based upon the input features which all are giving information about his nature/activity/age/etc.\n",
    "\n",
    "For example, as one would say,the students who scored and passed have attended the class in an average of about 70%. So the intuition is, probability is high if the students attend more classes.\n",
    "\n",
    "b. Our dataset is small with close to 400 samples. So i believe, Naive bayes is believed to yield good prediction.\n",
    "\n",
    "3. Support Vector Machines\n",
    "\n",
    "Strengths(I):\n",
    "\n",
    "1.High accuracy.Effective in high dimensional spaces. Kernel trick is the strength of this algorithm. With an appropriate kernel they can work well even if the data isn't linearly separable in the base feature space.(I)\n",
    "\n",
    "2.Still effective in cases where number of dimensions is greater than the number of samples\n",
    "\n",
    "3. Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "Weaknesses:\n",
    "\n",
    "1. Perhaps the biggest limitation of the support vector approach lies in choice of the kernel-selection of the kernel function parameters in high dimensional spaces.(II)\n",
    "\n",
    "2. A second limitation is speed and size, both in training and testing. (I)\n",
    "\n",
    "3. If the number of features is much greater than the number of samples, the method is likely to give poor performances.(II)\n",
    "\n",
    "4. SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation.(II)\n",
    "\n",
    "References:\n",
    "(I) https://www.quora.com/What-are-the-advantages-of-different-classification-algorithms\n",
    "(II) http://www.svms.org/disadvantages.html\n",
    "\n",
    "\n",
    "Reason for considering Support Vector Machines:\n",
    "\n",
    " a. Due to its accuracy in prediction of the students performances. Due to its highly predictive ability, this was one of the most important reason to pick up.\n",
    "\n",
    "b. Due to its advantage of being efficient at high dimensional spaces. So there is no constraint for not having linearly separable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.013\n"
     ]
    }
   ],
   "source": [
    "# Train a model\n",
    "import time\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print \"Training {}...\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    trainingtime=end-start\n",
    "    print \"Done!\\nTraining time (secs): {:.3f}\".format(trainingtime)\n",
    "    return trainingtime\n",
    "\n",
    "# TODO: Choose a model, import it and instantiate an object\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Fit model to training data\n",
    "DTC_trainingtime_300=train_classifier(clf, X_train, y_train)  # note: using entire training set here\n",
    "#print clf  # you can inspect the learned model by printing it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for training set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Predict on training set and compute F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    print \"Predicting labels using {}...\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    print \"Done!\\nPrediction time (secs): {:.3f}\".format(end - start)\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "train_f1_score = predict_labels(clf, X_train, y_train)\n",
    "print \"F1 score for training set: {}\".format(train_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.736842105263\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "print \"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.003\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for training set: 1.0\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for test set: 0.744525547445\n",
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.004\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for training set: 1.0\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.721804511278\n",
      "------------------------------------------\n",
      "Training set size: 300\n",
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.006\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 1.0\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for test set: 0.762589928058\n"
     ]
    }
   ],
   "source": [
    "# Train and predict using different training set sizes\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    print \"------------------------------------------\"\n",
    "    print \"Training set size: {}\".format(len(X_train))\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    print \"F1 score for training set: {}\".format(predict_labels(clf, X_train, y_train))\n",
    "    print \"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test))\n",
    "    \n",
    "train_predict(clf, X_train[0:100], y_train[0:100], X_test, y_test)\n",
    "train_predict(clf, X_train[0:200], y_train[0:200], X_test, y_test)\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# TODO: Run the helper function above for desired subsets of training data\n",
    "# Note: Keep the test set constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GaussianNB...\n",
      "Done!\n",
      "Training time (secs): 0.004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.003999948501586914"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf=GaussianNB()\n",
    "train_classifier(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training GaussianNB...\n",
      "Done!\n",
      "Training time (secs): 0.003\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for training set: 0.883720930233\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for test set: 0.69696969697\n",
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training GaussianNB...\n",
      "Done!\n",
      "Training time (secs): 0.003\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for training set: 0.798507462687\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for test set: 0.714285714286\n",
      "------------------------------------------\n",
      "Training set size: 300\n",
      "Training GaussianNB...\n",
      "Done!\n",
      "Training time (secs): 0.003\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for training set: 0.790816326531\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for test set: 0.744525547445\n"
     ]
    }
   ],
   "source": [
    "train_predict(clf, X_train[0:100], y_train[0:100], X_test, y_test)\n",
    "train_predict(clf, X_train[0:200], y_train[0:200], X_test, y_test)\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04900002479553223"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf=SVC()\n",
    "train_classifier(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.004\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for training set: 0.916666666667\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for test set: 0.858974358974\n",
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.007\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.008\n",
      "F1 score for training set: 0.870967741935\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.005\n",
      "F1 score for test set: 0.858895705521\n",
      "------------------------------------------\n",
      "Training set size: 300\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.018\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.014\n",
      "F1 score for training set: 0.864988558352\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.005\n",
      "F1 score for test set: 0.8625\n"
     ]
    }
   ],
   "source": [
    "train_predict(clf, X_train[0:100], y_train[0:100], X_test, y_test)\n",
    "train_predict(clf, X_train[0:200], y_train[0:200], X_test, y_test)\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Choosing the Best Model\n",
    "\n",
    "- Based on the experiments you performed earlier, in 1-2 paragraphs explain to the board of supervisors what single model you chose as the best model. Which model is generally the most appropriate based on the available data, limited resources, cost, and performance?\n",
    "- In 1-2 paragraphs explain to the board of supervisors in layman's terms how the final model chosen is supposed to work (for example if you chose a Decision Tree or Support Vector Machine, how does it make a prediction).\n",
    "- Fine-tune the model. Use Gridsearch with at least one important parameter tuned and with at least 3 settings. Use the entire training set for this.\n",
    "- What is the model's final F<sub>1</sub> score?\n",
    "\n",
    "Of all the chosen model, we should choose the model which performs optimally in processing time and F1 Score. The observations from the above results for the 3 different models are as below;\n",
    "\n",
    "1.Training time and prediction times are high for SVM in comparison to Decision Trees, Naïve Bayes. They increase considerably with respect to training set. And SVM comes with high average F1 score on test set.\n",
    "\n",
    "2.Training time is not consistent for Naïve Bayes with respect to increases in Training set.\n",
    "\n",
    "3. Average F1 Score on testing set with different training set for Decision trees is less than the other chosen classifiers.\n",
    "\n",
    "4. Gaussian Naïve Bayes is fast in training and classifying. After NB, Decision trees take less time to learn the training set among the chosen algorithms for all the training size.\n",
    "\n",
    "\n",
    "Since 'Processing time' and 'Optimum F1 Score' are the essentials to choose the best algorithm, here i propose Support Vector Machines algorithm for the given dataset where the accuracy is high though it comes at an expense of additional processing time in comparison.\n",
    "\n",
    "There are 2 most important reasons i gave as a reason for choosing SVM. They are;\n",
    "1.SVM's are accurate than the other chosen algorithms. Please look at the average F1 Score on testing set for all the chosen classifiers in the report. A difference in accuracy makes prediction for few or more students likely to join the program.\n",
    "\n",
    "2.Though SVM take more processing time than other 2 classifiers, the following are the convincing reality which we need to make;\n",
    "    a. First, the student interventions system model is required to learn and predict in a given time which is not critical in nature. For example, a High School teacher can expect to wait for an additional hour to know the predictions from the machine learning model. Less computing power increases the wait time.More computing power improves the performance time of machine learning algorithm where one can draw an intution upon AlphaGo whereas the thinking time is 2 seconds.https://en.wikipedia.org/wiki/AlphaGo\n",
    "    \n",
    "    b. We are not dealing with very critical output from our model within a very short moment. For example, in chemical process industries or oil refinery applications, the data should be processed quickly and get processed as quick to avoid any unsafe activity.But in our case, prediction of student performance can take an another several minutes oran hour based upon dataset. Satisfying the more accuracy gives more confidence in SVM.\n",
    "\n",
    "The chosen algorithm , Support Vector Machines work in the following way:\n",
    "\n",
    "Lets imagine , we place two colors of balls on the table and we want to segregate(classify) based upon the colors. You are given a scale / ruler to place on the table where an exact separation happens. How our intuition will decide where to place the ruler on the table between two different colors of balls.\n",
    "\n",
    "Yes, we will look for a place where the maximum liklihood of one set of balls with same color on one side and the another set of balls with another color will go on another side. So , we find a place which is in between these 2 different colors. And that place has space where in multiple ways the ruler can be placed on different angles. To choose the best placement, lets think for a while how this ruler can best be placed in that space. Yes, we would prefer the ruler to be placed closest to the middle in the gap/space between two different colors. In support vector machines we do the same,i.e. Classification. The distance between the ruler and the each side of color balls will be targeted to be maximum.\n",
    "\n",
    "Also SVM comes with trick called 'Kernel' which is used for handling the data which all are not linearly separable. \n",
    "\n",
    "In our example, lets say a kid comes and randomly plays the balls on the table and left it for you to palce a ruler to separate the two different colors of balls. Now there are no ordered balls on the table.\n",
    "\n",
    "That would be difficult task as the balls are no more segregated nicely as before and Ruler can not be straight away be used. Lets think and see how we can classify. \n",
    "\n",
    "One way to separate these balls is to increase the elevation of one set of balls with same color above. We can tie thread to balls with same color and lift above the table surface. This will give a different elevation from one set of balls with a color from another set of balls with different color.\n",
    "\n",
    "Now, if we look horizontally, the two sets of balls with different colors can be separable with the help of straight ruler. Here we introduced a new hero called 'Thread' to make it happen.\n",
    "\n",
    "As we can see, in Support Vector Machines, we add more features to existing set of features. In our above example, it is 'Thread'.\n",
    "\n",
    "In our student sets as well, we can see for example, a set of new features can be introduced. Students study time and travel time can be used to create a new feature called 'time management' which may classify into 'Good' or 'little Good' for students.\n",
    "\n",
    "I play an example video here for your reference.\n",
    "https://www.youtube.com/watch?v=3liCbRZPrZA\n",
    "\n",
    "We can see beautifully here how SVM works to play with features to convert the non-linearly separable data into linearly separable.\n",
    "\n",
    "In our student data set as well, we intend to classify the students who require intervention and who does not, using the similar way of drawing a best decision boundary. As we see, the data is not so linear where we can draw conclusion easily but requires techniques like kernel to use which comes along with SVM.\n",
    "\n",
    "References:\n",
    "https://www.udacity.com/course/viewer#!/c-ud726-nd/l-5447009165/e-2428048554/m-2436168579"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.012\n",
      "F1 score for training set: 0.816593886463\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.004\n",
      "F1 score for test set: 0.880503144654\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fine-tune your model and report the best F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer           \n",
    "from sklearn import grid_search\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "cv = StratifiedShuffleSplit(y_train, random_state=42)\n",
    "\n",
    "clf = SVC()\n",
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 200, 300, 400, 500, 600, 700],\n",
    "   'gamma': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6],\n",
    "   'kernel': ['rbf'], 'tol':[1e-3, 1e-4, 1e-5, 1e-6]\n",
    "  }\n",
    " ]\n",
    "\n",
    "f1_scorer = make_scorer(f1_score, pos_label=\"yes\")\n",
    "grid_search = grid_search.GridSearchCV(clf, param_grid, scoring=f1_scorer)\n",
    "grid_search.fit(X_train, y_train)\n",
    "reg = grid_search.best_estimator_\n",
    "train_f1_score = predict_labels(reg, X_train, y_train)\n",
    "print \"F1 score for training set: {}\".format(train_f1_score)\n",
    "print \"F1 score for test set: {}\".format(predict_labels(reg, X_test, y_test))\n",
    "\n",
    "# http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html\n",
    "#http://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final F1 score for test set is: 0.880503144654"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
